{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyadashrafkh/AlexEagles_mega_project/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0UFflHF0ZuR"
      },
      "source": [
        "## Object Detection Model training using YOLO\n",
        "References -\n",
        "- [Documentation](https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/#13-prepare-dataset-for-yolov5)\n",
        "- [Testing IoU](https://stackoverflow.com/questions/77565416/how-to-test-iou-score-after-training-a-yolo-model)\n",
        "- [IoU calculation](https://stackoverflow.com/questions/25349178/calculating-percentage-of-bounding-box-overlap-for-image-detector-evaluation)\n",
        "- [Hungarian Algorithm to match Bounding Boxes](https://gist.github.com/AruniRC/c629c2df0e68e23aff7dcaeef87c72d4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_mLyF510ZuT"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics -q\n",
        "!pip install fiftyone -q\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import os, sys\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "from fiftyone import ViewField as F\n",
        "import json, shutil\n",
        "from collections import defaultdict\n",
        "from itertools import product\n",
        "from functools import reduce\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import cv2\n",
        "\n",
        "np.random.seed(0)\n",
        "# Save to current directory\n",
        "curr_dir = os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5YpWMA00ZuV"
      },
      "outputs": [],
      "source": [
        "# Load dataset dir\n",
        "fo.config.dataset_zoo_dir = curr_dir\n",
        "\n",
        "# Define the 15 classes you want to include\n",
        "selected_classes = [\n",
        "    \"person\",\n",
        "    \"car\",\n",
        "    \"motorcycle\",\n",
        "    \"airplane\",\n",
        "    \"bus\",\n",
        "    \"boat\",\n",
        "    \"stop sign\",\n",
        "    \"snowboard\",\n",
        "    \"umbrella\",\n",
        "    \"sports ball\",\n",
        "    \"baseball bat\",\n",
        "    \"bed\",\n",
        "    \"tennis racket\",\n",
        "    \"suitcase\",\n",
        "    \"skis\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the data\n",
        "# By default, the following loads data for detections\n",
        "dataset = foz.load_zoo_dataset(\"coco-2017\",\n",
        "                            splits=['train'],\n",
        "                            shuffle=True,\n",
        "                            seed=0,\n",
        "                            max_samples=None,\n",
        "                            label_types=['detections'],\n",
        "                            only_matching=True,\n",
        "                            classes=selected_classes)"
      ],
      "metadata": {
        "id": "JTZF70nwq8Y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpX1v-rj0ZuV"
      },
      "outputs": [],
      "source": [
        "# Load the downloaded dataset\n",
        "coco_dataset = fo.Dataset.from_dir(\n",
        "    dataset_type=fo.types.COCODetectionDataset,\n",
        "    data_path='coco-2017/train/data',\n",
        "    labels_path='coco-2017/train/labels.json',\n",
        "    max_samples=None,\n",
        "    include_id=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfikrkY20ZuW"
      },
      "outputs": [],
      "source": [
        "# The above downloads all classes in COCO\n",
        "# We filter them to only have people using the following -\n",
        "coco_dataset.export(\n",
        "    labels_path=\"coco-2017/labels.json\",\n",
        "    dataset_type=fo.types.COCODetectionDataset,\n",
        "    classes=selected_classes,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "M3uy5CRLq2OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCxZgaJs0ZuW"
      },
      "outputs": [],
      "source": [
        "# We need to convert the dataset to YOLO format\n",
        "input_dir = curr_dir + \"/coco-2017/\"\n",
        "output_dir = \"/content/drive/MyDrive/yolo/\"\n",
        "\n",
        "images_folder = input_dir + \"train/data/\"\n",
        "\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "\tos.mkdir(output_dir)\n",
        "\n",
        "for split in ['train', 'test']:\n",
        "\tshutil.rmtree(output_dir + split, ignore_errors=True)\n",
        "\tos.mkdir(output_dir + split)\n",
        "\tos.mkdir(output_dir + split + '/images')\n",
        "\tos.mkdir(output_dir + split + '/labels')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWjTe3JS0ZuX",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "\n",
        "ground_truths = defaultdict(list)\n",
        "\n",
        "# Read the annotations\n",
        "with open(input_dir + 'labels.json', 'r') as f:\n",
        "\t\tdata = json.load(f)\n",
        "\n",
        "# Count number of annotations\n",
        "num_data = len(data['images'])\n",
        "print(f\"Total number of images are {num_data}\")\n",
        "\n",
        "# Choose 80-20 split\n",
        "num_train = np.floor(0.8*num_data)\n",
        "num_test = np.floor(0.2*num_data)\n",
        "print(num_train, num_test)\n",
        "\n",
        "# Match annotations to images and write in YOLO format\n",
        "count = 0\n",
        "\n",
        "id_ann = defaultdict(list)\n",
        "for ann in data['annotations']:\n",
        "\tid_ann[ann['image_id']].append(ann)\n",
        "\n",
        "for image in data['images']:\n",
        "\twidth = image['width']\n",
        "\theight = image['height']\n",
        "\tfilename = image['file_name'].split('.')[0]\n",
        "\tid = image['id']\n",
        "\n",
        "\t# Writing current object and copying image\n",
        "\tif count < num_train:\n",
        "\t\tsplit = 'train'\n",
        "\telse:\n",
        "\t\tsplit = 'test'\n",
        "\n",
        "\tf = open(f'{output_dir}{split}/labels/{filename}.txt', 'w')\n",
        "\n",
        "\tfor annotation in id_ann[id]:\n",
        "\t\tcurrent_category = annotation['category_id'] - 1\n",
        "\t\tx, y, w, h = annotation['bbox']\n",
        "\n",
        "\t\t# Finding midpoints\n",
        "\t\tx_centre = x + w/2\n",
        "\t\ty_centre = y + h/2\n",
        "\n",
        "\t\t# Normalization\n",
        "\t\tx_centre /= width\n",
        "\t\ty_centre /= height\n",
        "\t\tw /= width\n",
        "\t\th /= height\n",
        "\n",
        "\t\t# Limiting upto fix number of decimal places\n",
        "\t\tsx_centre = format(x_centre, '.6f')\n",
        "\t\tsy_centre = format(y_centre, '.6f')\n",
        "\t\tsw = format(w, '.6f')\n",
        "\t\tsh = format(h, '.6f')\n",
        "\n",
        "\n",
        "\t\tground_truths[image['file_name']].append([x_centre, y_centre, w, h])\n",
        "\n",
        "\t\tf.write(f\"{current_category} {sx_centre} {sy_centre} {sw} {sh}\\n\")\n",
        "\tf.close()\n",
        "\tshutil.copy(images_folder + image['file_name'], f'{output_dir}{split}/images/{filename}.jpg')\n",
        "\tcount += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print number of labels in each training and test directories\n",
        "\n",
        "import os\n",
        "\n",
        "def count_labels_in_directories(train_dir, test_dir):\n",
        "    \"\"\"Counts the number of labels in each training and testing directory.\n",
        "\n",
        "    Args:\n",
        "        train_dir: Path to the training directory.\n",
        "        test_dir: Path to the testing directory.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing the number of labels in the training and testing directories.\n",
        "    \"\"\"\n",
        "    print(train_dir, test_dir)\n",
        "    train_labels = 0\n",
        "    for filename in os.listdir(os.path.join(train_dir, 'labels')):\n",
        "      if filename.endswith(\".txt\"):\n",
        "        train_labels += 1\n",
        "\n",
        "    test_labels = 0\n",
        "    for filename in os.listdir(os.path.join(test_dir, 'labels')):\n",
        "      if filename.endswith(\".txt\"):\n",
        "        test_labels += 1\n",
        "\n",
        "    return train_labels, test_labels\n",
        "\n",
        "# Example usage (replace with your actual directory paths):\n",
        "output_dir = \"/content/drive/MyDrive/yolo/\"\n",
        "train_labels_count, test_labels_count = count_labels_in_directories(os.path.join(output_dir, 'train'), os.path.join(output_dir, 'test'))\n",
        "\n",
        "print(f\"Number of labels in the training directory: {train_labels_count}\")\n",
        "print(f\"Number of labels in the testing directory: {test_labels_count}\")"
      ],
      "metadata": {
        "id": "dSbd5c6bzKq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a code to detetrmine the size of each split in GB\n",
        "\n",
        "import os\n",
        "\n",
        "def get_directory_size(directory):\n",
        "  \"\"\"Returns the size of a directory in GB.\"\"\"\n",
        "  total_size = 0\n",
        "  for dirpath, dirnames, filenames in os.walk(directory):\n",
        "    for f in filenames:\n",
        "      fp = os.path.join(dirpath, f)\n",
        "      # skip if it is symbolic link\n",
        "      if not os.path.islink(fp):\n",
        "        total_size += os.path.getsize(fp)\n",
        "\n",
        "  return total_size / (1024 ** 3)  # Convert bytes to GB\n",
        "\n",
        "# Example usage (replace with your actual directory paths):\n",
        "output_dir = \"/content/drive/MyDrive/yolo/\"\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "test_dir = os.path.join(output_dir, 'test')\n",
        "\n",
        "\n",
        "train_size_gb = get_directory_size(train_dir)\n",
        "test_size_gb = get_directory_size(test_dir)\n",
        "\n",
        "print(f\"Size of the training directory: {train_size_gb:.2f} GB\")\n",
        "print(f\"Size of the testing directory: {test_size_gb:.2f} GB\")"
      ],
      "metadata": {
        "id": "ruXOb7zjEEjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4rQ07W70ZuX"
      },
      "outputs": [],
      "source": [
        "# Sample an image from the dataset for credibility\n",
        "train_images = os.listdir(\"/content/drive/MyDrive/yolo/test/images\")\n",
        "random_images = np.random.choice(train_images, 3)\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "for i, file in enumerate(random_images):\n",
        "    # Corrected the path to read from the train folder\n",
        "    img = cv2.imread(\"/content/drive/MyDrive/yolo/test/images/\" + file)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    h, w, _ = img.shape\n",
        "    anns = ground_truths[file]\n",
        "    for ann in anns:\n",
        "        start = (int((ann[0] - ann[2]/2)*w), int((ann[1] - ann[3]/2)*h))\n",
        "        end = (int((ann[0] + ann[2]/2)*w), int((ann[1] + ann[3]/2)*h))\n",
        "        img = cv2.rectangle(img, start, end, (0, 255, 0), 2)\n",
        "    ax[i].imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBvrlNUr0ZuY"
      },
      "outputs": [],
      "source": [
        "# Load model for training\n",
        "model = YOLO('yolov8n.pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "# Define paths\n",
        "save_dir = Path('/content/drive/MyDrive/models')  # Save to Google Drive or another persistent location\n",
        "save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Check if a checkpoint exists\n",
        "checkpoint_path = save_dir / 'last.pt'\n",
        "resume_training = checkpoint_path.exists()  # Check if a checkpoint exists to resume training\n",
        "\n",
        "# Train the model\n",
        "train_results = model.train(\n",
        "    data='config.yaml',\n",
        "    batch=16,\n",
        "    epochs=5,\n",
        "    plots=True,\n",
        "    device='mps',  # Use 'mps' for Apple Silicon or 'cuda' for NVIDIA GPUs\n",
        "    save_dir=save_dir,  # Save checkpoints to this directory\n",
        "    resume=resume_training,  # Resume training if a checkpoint exists\n",
        ")\n",
        "\n",
        "# Save the final model\n",
        "final_model_path = save_dir / 'final_model.pt'\n",
        "torch.save(model.state_dict(), final_model_path)\n",
        "print(f\"Final model saved to {final_model_path}\")"
      ],
      "metadata": {
        "id": "LAQgSKiFNrDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsaWwzNb0ZuY"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "# Device = mps is for Apple Silicon\n",
        "train_results = model.train(data='config.yaml', batch=16, epochs=5, plots=True, device='mps')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcoibHcJ0ZuZ"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save(filename='trained.pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model for training\n",
        "model = YOLO('yolov8n.yaml')"
      ],
      "metadata": {
        "id": "gKfU8M4avH9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "# Device = mps is for Apple Silicon\n",
        "train_results = model.train(data='config.yaml', batch=16, epochs=5, plots=True, device='0')"
      ],
      "metadata": {
        "id": "32OI0AhovLkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save(filename='trained2.pt')"
      ],
      "metadata": {
        "id": "0kqwYuRRvNda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jo875wvl0ZuZ"
      },
      "outputs": [],
      "source": [
        "# Load model from trained weights\n",
        "model.load('trained.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNs-mKpg0ZuZ"
      },
      "outputs": [],
      "source": [
        "def calc_iou(bb1, bb2):\n",
        "    b1_x1 = bb1[0] - bb1[2]/2\n",
        "    b1_x2 = bb1[0] + bb1[2]/2\n",
        "    b1_y1 = bb1[1] - bb1[3]/2\n",
        "    b1_y2 = bb1[1] + bb1[3]/2\n",
        "\n",
        "    b2_x1 = bb2[0] - bb2[2]/2\n",
        "    b2_x2 = bb2[0] + bb2[2]/2\n",
        "    b2_y1 = bb2[1] - bb2[3]/2\n",
        "    b2_y2 = bb2[1] + bb2[3]/2\n",
        "\n",
        "    # determine the coordinates of the intersection rectangle\n",
        "    x_left = max(b1_x1, b2_x1)\n",
        "    y_top = max(b1_y1, b2_y1)\n",
        "    x_right = min(b1_x2, b2_x2)\n",
        "    y_bottom = min(b1_y2, b2_y2)\n",
        "\n",
        "    if x_right < x_left or y_bottom < y_top:\n",
        "        return 0.0\n",
        "\n",
        "    # The intersection of two axis-aligned bounding boxes is always an\n",
        "    # axis-aligned bounding box\n",
        "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
        "\n",
        "    # compute the area of both AABBs\n",
        "    bb1_area = bb1[2]*bb1[3]\n",
        "    bb2_area = bb2[2]*bb2[3]\n",
        "\n",
        "    # compute the intersection over union by taking the intersection\n",
        "    # area and dividing it by the sum of prediction + ground-truth\n",
        "    # areas - the interesection area\n",
        "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
        "    assert iou >= 0.0\n",
        "    assert iou <= 1.0\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1xFfiMo0ZuZ"
      },
      "outputs": [],
      "source": [
        "# Test the data with IOU score\n",
        "test_images_folder = output_dir + 'test/images/'\n",
        "test_labels_folder = output_dir + 'test/labels'\n",
        "test_files = os.listdir(test_images_folder)\n",
        "sum_iou = 0\n",
        "ious = defaultdict(float)\n",
        "num_test = len(test_files)\n",
        "\n",
        "# Create a folder to save the results\n",
        "results_folder = output_dir + 'results/'\n",
        "if not os.path.exists(results_folder):\n",
        "\tos.mkdir(results_folder)\n",
        "\n",
        "# Iterate through the test files to test the performance\n",
        "for test_file in test_files:\n",
        "    res = model.predict(test_images_folder + test_file, classes=[0])\n",
        "    res[0].save(results_folder + test_file)\n",
        "\n",
        "    gt = ground_truths[test_file]\n",
        "    preds = res[0].boxes.xywhn.numpy()\n",
        "\n",
        "    if len(gt) == 0 or len(preds) == 0:\n",
        "         continue\n",
        "\n",
        "    combinations = list(product(gt, preds))\n",
        "    iou_matrix = np.zeros((len(gt), len(preds)))\n",
        "    for i in range(len(gt)):\n",
        "        for j in range(len(preds)):\n",
        "            iou_matrix[i, j] = calc_iou(gt[i], preds[j])\n",
        "\n",
        "    # Do the Hungarian matching algorithm\n",
        "    gt_idx, pred_idx = linear_sum_assignment(1 - iou_matrix)\n",
        "    assigned_ious = np.sort(iou_matrix[gt_idx, pred_idx])[-len(gt):]\n",
        "\n",
        "    # Compute mean across all instances in the image\n",
        "    mean_iou = np.mean(assigned_ious)\n",
        "\n",
        "    assert mean_iou <= 1.0\n",
        "\n",
        "    sum_iou += mean_iou\n",
        "    ious[test_file] = (mean_iou, assigned_ious)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhYZNwG50Zua"
      },
      "outputs": [],
      "source": [
        "# Calculate the mean across all test cases\n",
        "print(\"The average IoU across all test instances is\", sum_iou/num_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L74NNFak0Zua"
      },
      "outputs": [],
      "source": [
        "# Show some sample output results\n",
        "n_samples = 6\n",
        "random_tests = np.random.choice(test_files, n_samples)\n",
        "\n",
        "fig, ax = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "for t, test_file in enumerate(random_tests):\n",
        "    res = model.predict(test_images_folder + test_file, classes=[0])\n",
        "    preds = res[0].boxes.xywhn.numpy()\n",
        "    img = cv2.imread(test_images_folder + test_file)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    h, w, _ = img.shape\n",
        "    gt = ground_truths[test_file]\n",
        "\n",
        "    for ann in gt:\n",
        "        start = (int((ann[0] - ann[2]/2)*w), int((ann[1] - ann[3]/2)*h))\n",
        "        end = (int((ann[0] + ann[2]/2)*w), int((ann[1] + ann[3]/2)*h))\n",
        "        img = cv2.rectangle(img, start, end, (0, 255, 0), 2)\n",
        "\n",
        "    for ann in preds:\n",
        "        start = (int((ann[0] - ann[2]/2)*w), int((ann[1] - ann[3]/2)*h))\n",
        "        end = (int((ann[0] + ann[2]/2)*w), int((ann[1] + ann[3]/2)*h))\n",
        "        img = cv2.rectangle(img, start, end, (0, 0, 255), 2)\n",
        "\n",
        "    combinations = list(product(gt, preds))\n",
        "    iou_matrix = np.zeros((len(gt), len(preds)))\n",
        "    for i in range(len(gt)):\n",
        "        for j in range(len(preds)):\n",
        "            iou_matrix[i, j] = calc_iou(gt[i], preds[j])\n",
        "\n",
        "    # Do the Hungarian matching algorithm\n",
        "    gt_idx, pred_idx = linear_sum_assignment(1 - iou_matrix)\n",
        "    assigned_ious = np.sort(iou_matrix[gt_idx, pred_idx])[-len(gt):]\n",
        "\n",
        "    # Compute mean across all instances in the image\n",
        "    mean_iou = np.mean(assigned_ious)\n",
        "\n",
        "    ax[t // 3][t % 3].imshow(img)\n",
        "    if mean_iou > 1:\n",
        "        mean_iou = 0\n",
        "    ax[t // 3][t % 3].set_title(\"IoU Score:\" + str(mean_iou))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}